{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c065c24c",
   "metadata": {},
   "source": [
    "# Retrieval expérimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52045271",
   "metadata": {},
   "source": [
    "## 0. Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e788c4",
   "metadata": {},
   "source": [
    "### 0.1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3b020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5dcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bed52753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation.qa.generate_chain import QAGenerateChain\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04483a2",
   "metadata": {},
   "source": [
    "### 0.2. Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cba9a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_folder_path = '../data/chunks'\n",
    "chunks_dataset_csv_file_path = '../data/csv/validation_template.csv'\n",
    "qa_dataset_csv_file_path = '../data/csv/validation_auto_qg.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebdd744",
   "metadata": {},
   "source": [
    "## 1.Create a data set for Question answering testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f3c9d",
   "metadata": {},
   "source": [
    "### 1.1. A bunch of chunks dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e79a1",
   "metadata": {},
   "source": [
    "#### commentaire : resort la liste entière de tout mes chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41838636",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = sorted(os.listdir(chunks_folder_path))\n",
    "nb_chunks = len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf5c3b",
   "metadata": {},
   "source": [
    "#### commentaire: \n",
    "-  on prends le 1/10 **`au hasard`** des chunk comme pour du testing classique\n",
    "- avoir plus tard si une analyse sur la distribution des données et des thématique ne pourrais pas aidé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ee304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random.sample(chunks, int(nb_chunks/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7631867",
   "metadata": {},
   "source": [
    "#### commentaire: génration du fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6da9eff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fichier ../data/csv/validation_template.csv généré avec 153 chunks.\n"
     ]
    }
   ],
   "source": [
    "with open(chunks_dataset_csv_file_path, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['chunk_id', 'text', 'question', 'reference_answer'])\n",
    "    for fname in sample:\n",
    "        text = open(os.path.join(chunks_folder_path, fname), encoding='utf-8').read()\n",
    "        snippet = text.replace('\\n', ' ') + '…'\n",
    "        writer.writerow([fname, snippet, '', ''])\n",
    "print(f\"fichier {chunks_dataset_csv_file_path} généré avec {len(sample)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d1e2a",
   "metadata": {},
   "source": [
    "### 1.2. Generations des questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cd6e13",
   "metadata": {},
   "source": [
    "##### 1.2.1. QG avec un modèle pré-entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f4abe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qa_1, tokenizer_qa_1 = \"valhalla/t5-base-e2e-qg\", \"valhalla/t5-base-e2e-qg\"\n",
    "model_qa_2, tokenizer_qa_2 = \"t5-small\", \"t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d0db329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\regis\\Documents\\aivancity\\pge4\\clinique\\chatbot\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\regis\\Documents\\aivancity\\pge4\\clinique\\chatbot\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\regis\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# Pipeline end-to-end QG\n",
    "qg = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model_qa_2,\n",
    "    tokenizer=tokenizer_qa_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11ddbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(chunks_dataset_csv_file_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6d654ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chunk_id', 'text', 'question', 'reference_answer'], dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec8faf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: generate question: real-world, in-home environments, as this is where most seizures progressinthefie...\n",
      "OUTPUT: non-EEG datastrictlyforneurologicalresearchanddoesnotstoreanynon-EEG detectionsystemscanbemodelledtoaccuratelyreflectthereal-world resources\n",
      "--------------------------------------------------\n",
      "Exemple QA générée : {'question': 'non-EEG datastrictlyforneurologicalresearchanddoesnotstoreanynon-EEG detectionsystemscanbemodelledtoaccuratelyreflectthereal-world resources?', 'reference_answer': 'complexities encountered by PWE in their day to day lives'}\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for chunk_id, snippet, _, _ in df.itertuples(index=False):\n",
    "    # Prompt plus simple et direct\n",
    "    prompt = f\"generate question: {snippet}\"\n",
    "    \n",
    "    # Paramètres ajustés pour de meilleures générations\n",
    "    out = qg(\n",
    "        prompt,\n",
    "        max_length=100,  # Augmenté pour avoir plus de contexte\n",
    "        min_length=10,   # Longueur minimale\n",
    "        num_beams=5,     # Plus de beams pour de meilleurs résultats\n",
    "        num_return_sequences=1,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,  # Ajout de sampling\n",
    "        temperature=0.7, # Contrôle de la créativité\n",
    "        clean_up_tokenization_spaces=True\n",
    "    )[0]['generated_text'].strip()\n",
    "\n",
    "    print(f\"PROMPT: {prompt[:100]}...\")\n",
    "    print(f\"OUTPUT: {out}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Parsing amélioré\n",
    "    question = out\n",
    "    if not question.endswith('?'):\n",
    "        question += '?'\n",
    "    \n",
    "    # Génération de la réponse séparément\n",
    "    answer_prompt = f\"answer the question based on context: {question} Context: {snippet}\"\n",
    "    answer_out = qg(\n",
    "        answer_prompt,\n",
    "        max_length=80,\n",
    "        num_beams=3,\n",
    "        num_return_sequences=1,\n",
    "        early_stopping=True\n",
    "    )[0]['generated_text'].strip()\n",
    "    \n",
    "    if question and len(question) > 5:\n",
    "        rows.append({\n",
    "            'chunk_id': chunk_id,\n",
    "            'question': question,\n",
    "            'reference_answer': answer_out\n",
    "        })\n",
    "    \n",
    "    break  # pour test\n",
    "\n",
    "# 5. Construire et afficher le DataFrame résultat\n",
    "df_out = pd.DataFrame(rows)\n",
    "print(\"Exemple QA générée :\", df_out.dropna().iloc[0][['question','reference_answer']].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad2554",
   "metadata": {},
   "source": [
    "##### 1.2.2. mistral from ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c85c3",
   "metadata": {},
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "response = llm.invoke([{\"role\": \"user\", \"content\": \"Bonjour, peux-tu me dire le capital de la France ?\"}])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f64ec",
   "metadata": {},
   "source": [
    "#### 1.2.2.1. question answer completion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "077f98f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(chunks_dataset_csv_file_path)\n",
    "texts = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9277dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openlyaccessibledatabaseencompassingnon-EEGsensordatafrom OpenSeizureDatabase/blob/main/documentation/ multiple sensing modalities. LICENCE.md Thisstudydistinguishesitselfbyutilisingreal-worlddata,provid- ing an accurate depiction of everyday life compared to controlled Informed Consent Statement: The users gave their consent EMU-based datasets. The beta trial’s success led to an indefinite to publish the developed database by agreeing to the Privacy extension of the data collection period, showcasing our commitment Policy at https://github.com/OpenSeizureDetector/ to continually enriching the OSDB and contributing to non-EEG OpenSeizureDatabase/blob/main/documentation/…'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f357aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"mistral\")\n",
    "qag = QAGenerateChain.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a5f8527",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = qag.batch(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceaf6d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c775bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'doc': 'openlyaccessibledatabaseencompassingnon-EEGsensordatafrom OpenSeizureDatabase/blob/main/documentation/ multiple sensing modalities. LICENCE.md Thisstudydistinguishesitselfbyutilisingreal-worlddata,provid- ing an accurate depiction of everyday life compared to controlled Informed Consent Statement: The users gave their consent EMU-based datasets. The beta trial’s success led to an indefinite to publish the developed database by agreeing to the Privacy extension of the data collection period, showcasing our commitment Policy at https://github.com/OpenSeizureDetector/ to continually enriching the OSDB and contributing to non-EEG OpenSeizureDatabase/blob/main/documentation/…', 'qa_pairs': {'query': 'What is the name of the database used in this study, and where can one find more information about its licence?', 'answer': 'The name of the database used in this study is the OpenSeizureDatabase. More information about its licence can be found at https://github.com/OpenSeizureDetector/.'}}\n"
     ]
    }
   ],
   "source": [
    "print(results[121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "deec9038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\regis\\AppData\\Local\\Temp\\ipykernel_8688\\347856082.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'What network achieved top-5 test accuracy of 93.3% in the 2014 ImageNet competition, and what is it called?' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[i, \"question\"] = qap.get(\"query\", \"\")\n",
      "C:\\Users\\regis\\AppData\\Local\\Temp\\ipykernel_8688\\347856082.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'GoogLeNet' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[i, \"reference_answer\"] = qap.get(\"answer\", \"\")\n"
     ]
    }
   ],
   "source": [
    "for i, res in enumerate(results):\n",
    "    qap = res.get(\"qa_pairs\", {})\n",
    "    df.at[i, \"question\"] = qap.get(\"query\", \"\")\n",
    "    df.at[i, \"reference_answer\"] = qap.get(\"answer\", \"\")\n",
    "df.to_csv(qa_dataset_csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
